{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN+OPYw75BH9919aDIWcs0r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"lpo6VUfoLobp"},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon Aug 19 11:47:15 2019\n","\n","@author: isswan\n","\"\"\"\n","\n","#pip install nltk\n","#nltk.download('stopwords')\n","#nltk.download('punkt')\n","\n","####################Data Preparation \n","import pandas as pd\n","news=pd.read_table('r8-train-all-terms.txt',header=None,names = [\"Class\", \"Text\"])\n","news.head()\n","a = news.groupby(\"Class\")\n","a.head()\n","\n","news.groupby('Class').describe()\n","\n","#Select a subset from the dataframe. (crude money-fx trade)\n","subnews=news[(news.Class==\"trade\")| (news.Class=='crude')|(news.Class=='money-fx') ]\n","\n","subnews.groupby('Class').describe()\n","print(subnews.shape)\n","\n","#Count the length of each document\n","length=subnews['Text'].apply(len)\n","subnews=subnews.assign(Length=length)\n","subnews.head()\n","\n","#Plot the distribution of the document length for each category\n","import matplotlib.pyplot as plt\n","subnews.hist(column='Length',by='Class',bins=50)\n","\n","plt.figure()\n","\n","#####################Data preprocessing \n","\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","newstopwords=stopwords.words(\"english\") + ['the','is','it','may']\n","newstopwords = ['the','is','it','may']\n","WNlemma = nltk.WordNetLemmatizer()\n","\n","\n","def pre_process(text):\n","    tokens = nltk.word_tokenize(text)\n","    tokens=[WNlemma.lemmatize(t) for t in tokens]\n","    tokens=[word for word in tokens if word not in newstopwords]\n","    text_after_process=\" \".join(tokens)\n","    return(text_after_process)\n","\n","#Apply the function on each document\n","subnews['Text'] = subnews['Text'].apply(pre_process)\n","\n","subnews.head()\n","\n","#Count the length of each document\n","length=subnews['Text'].apply(len)\n","subnews=subnews.assign(Length=length)\n","\n","#####################Data Split and Create DTM\n","#split the data into training and testing\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(subnews.Text, subnews.Class, test_size=0.30, random_state=12)\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","count_vect = CountVectorizer()\n","\n","#####################Build training pipeline using  Na√Øve Bayes Model\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.naive_bayes import MultinomialNB\n","\n","text_clf = Pipeline([('vect', CountVectorizer()),   #Vectorizer\n","                     ('tfidf', TfidfTransformer()), #DTM with TFIDF\n","                      ('clf', MultinomialNB()),     #ML Model\n","                    ])\n","\n","text_clf.fit(X_train,y_train ) \n","\n","##Evaluate the model\n","import numpy as np\n","from sklearn import metrics \n","predicted = text_clf.predict(X_test)\n","print(metrics.confusion_matrix(y_test, predicted))\n","print(\"NB:\",np.mean(predicted == y_test) )\n","\n","#####################Build training pipeline using  Decision Tree Model\n","from sklearn import tree\n","text_clf = Pipeline([('vect', CountVectorizer()),\n","                     ('tfidf', TfidfTransformer()),\n","                      ('clf', tree.DecisionTreeClassifier())\n","                    ])\n","clf = text_clf.fit(X_train, y_train) \n","\n","predicted = clf.predict(X_test)\n","\n","print(metrics.confusion_matrix(y_test, predicted))\n","print(\"DT:\",np.mean(predicted == y_test) )\n","  \n","#####################Build training pipeline using  SVM Model\n","from sklearn import svm\n","from sklearn.svm import SVC\n","\n","from sklearn.linear_model import SGDClassifier\n","text_clf = Pipeline([('vect', CountVectorizer()),\n","                     ('tfidf', TfidfTransformer(use_idf=True)),\n","                      ('clf', svm.LinearSVC(C=1.0))\n","                    ])\n","text_clf.fit(X_train, y_train) \n","    \n","predicted = text_clf.predict(X_test)\n"," \n","print(metrics.confusion_matrix(y_test, predicted))\n","print(np.mean(predicted == y_test) )\n","print(metrics.classification_report(y_test, predicted))\n","########################Prediction on new documents\n","docs_new = ['Crude price is dropping ', 'interest rate is increasing']\n","predicted = text_clf.predict(docs_new)\n","print(predicted)"],"execution_count":null,"outputs":[]}]}