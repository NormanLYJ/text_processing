System Architecture

I will be continuing by talking about the system architecture
The architecture can be breakdown into 3 major, stages Indexing, Training, and Serving

Indexing Stage We will craw the raw text data from inmvestopedia, and then do a little bit cleaning to strip off unnecessary content  and noises, 

Then we will parse the document, and perform some enrichment.
The enrichment was meant to inject some meta data to the document eg author, published date, popularity etc.
These are useful in later stage when we perform the search result rankling.
It is a important aspect for a full bloown search engine but not very relevant to the scope of this course, so we 
will not have this process.

Now once we have the cleaned raw text, we will save it as an index into ElasticSearch, this is called indexing process.

Here ElasticSearch will act as a reliable document store. Running inside container.
ElasticSearch which use an algorithm called BM25 natively as apose to  tf-idf for sparse retrieval, it also support dense retrieval that is vector embedding based. That dense retrieval capability is what we will be using, we will not use their native BM25 or inverted index based retrival


Now once we have the document indexed into ES, we will be doing some finetuning process 
We will be using models from huggingface and will be finetuning 2 transformer based model, one for semantic search,. One for QA
For the QA model, we first will be manually preparing some SQUAD dataset, which contains the question and position of the answer from the corpus. We will take the SQUAD in json  as well as as the raw corpus in the store for the finetuning



For the model serving, 

We will serve the 2 models independently, the models will be exposed as a GraphQL api endpoint
GraphQL is an alternative to REST api which allows a graph approach to define data communications

Then we will have a API Gateway which performs the schema federation and stitch the apis as a single entry point for the client. So this really forms a micro service architecture. Though it is small as this stage, but it is easily scalable to include more apis in future

Finally we will have the UI, when user ask for a key word, a phrase, or even a question.
We will throw the query to both models, the QA model tries to find the best and concise response to the query, and return to the user, and then it take the next query and perform the same thing, so that the conversation can go on.

The semanticSearch api, on the other hand, takes the query, does the search in the document store, find the top K most relevant documents, and return the list to user.

show UI
This is the how the UI will look like, the conversion is on the right, and it is continuous.
The search result is on the left, So it is a  hybrid solution 
Of course this is mocked up at this moment.


Now I will talk about the details of the 2 pipelines
we will be using a python framework call Haystack, developed by deepset-ai
It provide some high level abstraction of building am indexing pipeline and searching pipeline



For the search, we will pass the document to the retriever, which is a vector based model, it apply embedding to both the passage and the documents, and perform similarity evaluation.
We are planning to use sentence-transformer here,
sentence-transformer is an implementation of sentence-BERT which is based on BERT but more suited for semantic similarity evaluation

For the QA

it is very similar to the search, but there is an additional stage called reader, reader actually reads all the candidate documents return by the retriever, it will extract the top k best answers.
reader model were trained with SQUAD dataset 



Tech/tool selection
We will use Beuatifulsoup python module for data crawling
We will do the manual data annoation for QA model using some tools like haystack annotator
We wil use ElasticSearch as document store, it will run inside docker container. 

We are also  evaluating other alternatives eg weaviate which is a new search engine that is vector based, but it is still under heavy development so it is not very stable at the moment. Milvus and FAISS are also another vector based search engine, very similar,  but the problem is that they are in-memory, not good for long term project.

For the search model, we are using sentence-tranformer, stsb (pretained on semantic textual similarity benchmark)
For the QA model, we will start with some roberta model already trained on SQUAD
For API, we use deepset's Haystack, and use Apollo gateway for api gateway
For UI, react, with Apollo client, which talks to the gateway


This is the project  planning
These are the major tasks as I already mentioned
Some small component has completed
Majority effort is still on on data annotation and model training


Future enhancement:
larger corpus coverage, right now only on invespopedia, maybe we can extent to other website, or include more topics
Improve model performance - something applicable to any ML project
Auto completion - introduce language model to predict the next word as user types, similar to what google is offering


